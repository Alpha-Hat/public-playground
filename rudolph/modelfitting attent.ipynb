{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:06:37.704393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733331997.718046   40651 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733331997.722194   40651 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-04 17:06:37.737559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, MultiHeadAttention, LayerNormalization, Add\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\n",
      "\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\n",
      "Do not attempt too much at once.\n",
      "\n",
      "\n",
      "\n",
      "Return to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\n",
      "Or read more short stories for kids in ourChildren's Library\n",
      "into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren's filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then\n"
     ]
    }
   ],
   "source": [
    "%run '/home/ec2-user/kaggle/rudolph/dataPrep.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\n",
      "\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\n",
      "Do not attempt too much at once.\n",
      "\n",
      "\n",
      "\n",
      "Return to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\n",
      "Or read more short stories for kids in ourChildren's Library\n",
      "into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren's filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then\n"
     ]
    }
   ],
   "source": [
    "print(stories[0][0])\n",
    "print(stories[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset: Pairs of original and scrambled sentences \n",
    "\"\"\"\n",
    "sentences = [\n",
    "    (\"I love programming\", \"programming I love\"),\n",
    "    (\"Keras makes deep learning easy\", \"makes easy Keras deep learning\"),\n",
    "    (\"The cat sat on the mat\", \"on the mat The cat sat\"),\n",
    "    (\"Hello world\", \"world Hello\"),\n",
    "    (\"Pine Cone and Pepper Pot ran after her. Jeremy Mouse only stuck his head out of the snow cave. He didn’t want Jack Frost to nip his toes and certainly not his tail! Jack Frost! Jack Frost! cried Tiptoes. We’ve come to pay a visit. Jack Frost landed next to them. He was pale, icy blue, and his arms and fingers were long and glistening. His eyes were sharp, and his wings crackled like breaking ice whenever he moved. He looked so fierce that Pine Cone and Pepper Pot were afraid to open their mouths. It became so chilly they wrapped their beards round their necks and pulled their hats over their ears.\", \"snow he beards only fingers so out their We’ve of and came his sharp, they Cone her. afraid glistening. he Jack long, their It Jack He open his Pot! was to Pot and hats nip after not He necks the ears. Jeremy over Jack next icy Mouse round moved. He tail! was pale, the pay their icy pine wrapped their didn’t heads ice fierce glistening. mouths. breaking over pay Jack next like arms his moved. and certainly! only out was the look Tiptoes over not mouths. and he his to Pepper afraid cave. him Jeremy stuck crackled came blue, pulled ran his round with tail! He them. Mouse after didn’t nip fingers wings their not tail! mouse Pot afraid stuck arms of toes icy Cone was them pay. Pine wings came Pepper their He fierce long his wings Cone hats icy his over and next certainly Jack after ears. glistening. pay tiptoes! like pine ran was icy cave! certainly moved the.\"),\n",
    "    (\"Machine learning is fascinating\", \"fascinating Machine is learning\"),\n",
    "]\n",
    "\"\"\"\n",
    "sentences = stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I love programming', 'programming I love')\n",
      "('A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\\n\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\\nDo not attempt too much at once.\\n\\n\\n\\nReturn to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\\nOr read more short stories for kids in ourChildren\\'s Library', 'into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren\\'s filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then')\n"
     ]
    }
   ],
   "source": [
    "#print(sentences[0])\n",
    "#print(stories[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Add <start> and <end> tokens to the original sentences because it seems to break the algorithm without them\n",
    "original_sentences = [f\"<start> {s[0]} <end>\" for s in sentences]\n",
    "scrambled_sentences = [s[1] for s in sentences]\n",
    "\n",
    "# Tokenize and preprocess sentences\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(original_sentences + scrambled_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "max_seq_length = max(\n",
    "    max(len(seq.split()) for seq in scrambled_sentences),\n",
    "    max(len(seq.split()) for seq in original_sentences),\n",
    ")\n",
    "#max_seq_length = 46914 #inputted to avoid resource drain of run data prep file.\n",
    "# Convert sentences to sequences and pad\n",
    "input_sequences = pad_sequences(tokenizer.texts_to_sequences(scrambled_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "target_sequences = pad_sequences(tokenizer.texts_to_sequences(original_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "\n",
    "# Create target sequences for teacher forcing\n",
    "target_input_sequences = target_sequences[:, :-1]\n",
    "target_output_sequences = target_sequences[:, 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_dim = 256\n",
    "latent_dim = 256\n",
    "num_heads = 4\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_seq_length,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs = Dense(latent_dim)(encoder_embedding)\n",
    "\n",
    "# Additional encoder layer\n",
    "encoder_dense_2 = Dense(latent_dim, activation=\"relu\")(encoder_outputs)\n",
    "encoder_outputs = Add()([encoder_outputs, encoder_dense_2])  # Residual connection\n",
    "encoder_outputs = LayerNormalization()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_seq_length - 1,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "\n",
    "# Self-Attention\n",
    "decoder_self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=latent_dim)(decoder_embedding, decoder_embedding)\n",
    "decoder_self_attention = Add()([decoder_embedding, decoder_self_attention])\n",
    "decoder_self_attention = LayerNormalization()(decoder_self_attention)\n",
    "\n",
    "# Cross-Attention\n",
    "decoder_cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=latent_dim)(decoder_self_attention, encoder_outputs)\n",
    "decoder_cross_attention = Add()([decoder_self_attention, decoder_cross_attention])\n",
    "decoder_cross_attention = LayerNormalization()(decoder_cross_attention)\n",
    "\n",
    "# Feed-forward layers\n",
    "decoder_ffn = Dense(latent_dim * 4, activation=\"relu\")(decoder_cross_attention)\n",
    "decoder_ffn = Dense(latent_dim)(decoder_ffn)\n",
    "decoder_ffn = Add()([decoder_cross_attention, decoder_ffn])  # Residual connection\n",
    "decoder_ffn = LayerNormalization()(decoder_ffn)\n",
    "\n",
    "# Additional feed-forward block\n",
    "decoder_ffn_2 = Dense(latent_dim * 4, activation=\"relu\")(decoder_ffn)\n",
    "decoder_ffn_2 = Dense(latent_dim)(decoder_ffn_2)\n",
    "decoder_ffn_2 = Add()([decoder_ffn, decoder_ffn_2])  # Residual connection\n",
    "decoder_ffn_2 = LayerNormalization()(decoder_ffn_2)\n",
    "\n",
    "# Output layer\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(decoder_ffn_2)\n",
    "\n",
    "# Compile model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Prep train and test data -went with '42' for seed because it's the joke that keeps on giving\n",
    "decoder_target_output = np.expand_dims(target_output_sequences, -1)\n",
    "X_train, X_test, y_train, y_test, decoder_y_train, decoder_y_test = train_test_split(\n",
    "    input_sequences, target_input_sequences, decoder_target_output, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5353 - loss: 3.2404 - val_accuracy: 0.4976 - val_loss: 3.8861\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5368 - loss: 3.1796 - val_accuracy: 0.4999 - val_loss: 3.8801\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5521 - loss: 3.1179 - val_accuracy: 0.4992 - val_loss: 3.8727\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.5582 - loss: 3.0593 - val_accuracy: 0.5001 - val_loss: 3.8715\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5716 - loss: 3.0009 - val_accuracy: 0.5021 - val_loss: 3.8731\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5804 - loss: 2.9439 - val_accuracy: 0.5020 - val_loss: 3.8735\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5845 - loss: 2.8869 - val_accuracy: 0.5016 - val_loss: 3.8779\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5892 - loss: 2.8338 - val_accuracy: 0.5017 - val_loss: 3.8822\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5957 - loss: 2.7791 - val_accuracy: 0.5013 - val_loss: 3.8845\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6011 - loss: 2.7261 - val_accuracy: 0.5018 - val_loss: 3.8851\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6037 - loss: 2.6743 - val_accuracy: 0.5029 - val_loss: 3.8873\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6077 - loss: 2.6239 - val_accuracy: 0.5023 - val_loss: 3.8928\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6124 - loss: 2.5745 - val_accuracy: 0.5016 - val_loss: 3.9005\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6164 - loss: 2.5268 - val_accuracy: 0.5016 - val_loss: 3.9065\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6188 - loss: 2.4800 - val_accuracy: 0.5027 - val_loss: 3.9104\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6198 - loss: 2.4342 - val_accuracy: 0.5025 - val_loss: 3.9153\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6209 - loss: 2.3902 - val_accuracy: 0.5020 - val_loss: 3.9228\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6226 - loss: 2.3477 - val_accuracy: 0.5011 - val_loss: 3.9317\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6234 - loss: 2.3068 - val_accuracy: 0.5013 - val_loss: 3.9392\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6241 - loss: 2.2670 - val_accuracy: 0.5012 - val_loss: 3.9463\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6247 - loss: 2.2289 - val_accuracy: 0.5000 - val_loss: 3.9547\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6251 - loss: 2.1924 - val_accuracy: 0.4999 - val_loss: 3.9646\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6261 - loss: 2.1571 - val_accuracy: 0.5005 - val_loss: 3.9738\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6271 - loss: 2.1232 - val_accuracy: 0.5007 - val_loss: 3.9823\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6277 - loss: 2.0906 - val_accuracy: 0.5001 - val_loss: 3.9928\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6283 - loss: 2.0594 - val_accuracy: 0.4994 - val_loss: 4.0054\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6289 - loss: 2.0293 - val_accuracy: 0.4988 - val_loss: 4.0169\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6294 - loss: 2.0005 - val_accuracy: 0.4989 - val_loss: 4.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6300 - loss: 1.9730 - val_accuracy: 0.4992 - val_loss: 4.0387\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6306 - loss: 1.9468 - val_accuracy: 0.4991 - val_loss: 4.0519\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6317 - loss: 1.9216 - val_accuracy: 0.4987 - val_loss: 4.0632\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6330 - loss: 1.8975 - val_accuracy: 0.4995 - val_loss: 4.0742\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6340 - loss: 1.8746 - val_accuracy: 0.4993 - val_loss: 4.0875\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6350 - loss: 1.8527 - val_accuracy: 0.4993 - val_loss: 4.1004\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6360 - loss: 1.8317 - val_accuracy: 0.4993 - val_loss: 4.1126\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6373 - loss: 1.8117 - val_accuracy: 0.4991 - val_loss: 4.1254\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6378 - loss: 1.7926 - val_accuracy: 0.4987 - val_loss: 4.1375\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6388 - loss: 1.7743 - val_accuracy: 0.4988 - val_loss: 4.1507\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6401 - loss: 1.7568 - val_accuracy: 0.4980 - val_loss: 4.1618\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6417 - loss: 1.7401 - val_accuracy: 0.4980 - val_loss: 4.1751\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6428 - loss: 1.7242 - val_accuracy: 0.4974 - val_loss: 4.1893\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6441 - loss: 1.7090 - val_accuracy: 0.4969 - val_loss: 4.2014\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6452 - loss: 1.6944 - val_accuracy: 0.4967 - val_loss: 4.2145\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6466 - loss: 1.6805 - val_accuracy: 0.4971 - val_loss: 4.2255\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6478 - loss: 1.6674 - val_accuracy: 0.4962 - val_loss: 4.2418\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6486 - loss: 1.6558 - val_accuracy: 0.4962 - val_loss: 4.2470\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6484 - loss: 1.6498 - val_accuracy: 0.4951 - val_loss: 4.2895\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6493 - loss: 1.6498 - val_accuracy: 0.4977 - val_loss: 4.2572\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6475 - loss: 1.6352 - val_accuracy: 0.4954 - val_loss: 4.2909\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6517 - loss: 1.6154 - val_accuracy: 0.4950 - val_loss: 4.3251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f035b8c51f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the decoder model \n",
    "print(\"Training the decoder model...\")\n",
    "model.fit(\n",
    "    [X_train, y_train], decoder_y_train,\n",
    "    validation_data=([X_test, y_test], decoder_y_test),\n",
    "    batch_size=60,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model because it takes forever to fit the damn thing (i.e. 30min to fit an <1sec to load a saved model)\n",
    "model.save(\"/home/ec2-user/kaggle/rudolph/model_v0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call saved model (note: keras file is too big to save on github so make sure to add in your .gitignore file)\n",
    "\n",
    "model = load_model(\"/home/ec2-user/kaggle/rudolph/model_v0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# Decoder for inference\n",
    "decoder_inputs_inf = Input(shape=(max_seq_length - 1,))\n",
    "decoder_embedding_inf = Embedding(vocab_size, embedding_dim)(decoder_inputs_inf)\n",
    "\n",
    "decoder_self_attention_inf = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_embedding_inf, decoder_embedding_inf)\n",
    "decoder_self_attention_inf = Add()([decoder_embedding_inf, decoder_self_attention_inf])\n",
    "decoder_self_attention_inf = LayerNormalization()(decoder_self_attention_inf)\n",
    "\n",
    "decoder_cross_attention_inf = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_self_attention_inf, encoder_outputs)\n",
    "decoder_cross_attention_inf = Add()([decoder_self_attention_inf, decoder_cross_attention_inf])\n",
    "decoder_cross_attention_inf = LayerNormalization()(decoder_cross_attention_inf)\n",
    "\n",
    "decoder_ffn_inf = Dense(latent_dim * 4, activation=\"relu\")(decoder_cross_attention_inf)\n",
    "decoder_ffn_inf = Dense(latent_dim)(decoder_ffn_inf)\n",
    "decoder_ffn_inf = Add()([decoder_cross_attention_inf, decoder_ffn_inf])\n",
    "decoder_ffn_inf = LayerNormalization()(decoder_ffn_inf)\n",
    "\n",
    "decoder_outputs_inf = Dense(vocab_size, activation=\"softmax\")(decoder_ffn_inf)\n",
    "\n",
    "decoder_model = Model([decoder_inputs_inf, encoder_outputs], decoder_outputs_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardest part of the project (for me at least) -  function to decode scrambled sentences\n",
    "\"\"\"\n",
    "Requirements:\n",
    "1. ensuring the output is a permutation or original words\n",
    "2. mask words that are not included in the original scrambled sentenc\n",
    "3. mask words from the original scrambled sentence that are already used (unless they have multiple counts then count down until 0)\n",
    "\"\"\"\n",
    "def decode_sequence(input_seq, scrambled_sentence):\n",
    " \n",
    "    # Encode the input to get the context vector\n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Tokenize the scrambled sentence to get word counts\n",
    "    scrambled_words = scrambled_sentence.split()\n",
    "    word_count = Counter(scrambled_words)\n",
    "\n",
    "    # Generate the initial target sequence with the start token\n",
    "    target_seq = np.zeros((1, max_seq_length - 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[\"<start>\"]\n",
    "\n",
    "    # Initialize variables for decoding\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    used_words = set()\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Predict the next token probabilities\n",
    "        output_tokens = decoder_model.predict([target_seq, encoder_output])\n",
    "\n",
    "        # Create a mask for valid words\n",
    "        valid_word_indices = []\n",
    "        for word, count in word_count.items():\n",
    "            if count > 0:  # Only include words still available in scrambled input\n",
    "                token_index = tokenizer.word_index.get(word, None)\n",
    "                if token_index is not None:\n",
    "                    valid_word_indices.append(token_index)\n",
    "\n",
    "        # Mask out probabilities of words that are not in the scrambled set\n",
    "        if valid_word_indices:\n",
    "            mask = np.ones(output_tokens[0, -1, :].shape, dtype=bool)\n",
    "            mask[valid_word_indices] = False  # Only allow valid word indices\n",
    "            output_tokens[0, -1, mask] = 0\n",
    "        else:\n",
    "            # No valid words left, terminate decoding\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Resample words from the scambled set\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, None)\n",
    "\n",
    "        # keep track of used words that haven't been over used, and add then to the used word list\n",
    "        if sampled_word in word_count and word_count[sampled_word] > 0:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "            word_count[sampled_word] -= 1\n",
    "            used_words.add(sampled_word)\n",
    "\n",
    "        # check progress \n",
    "        print(f\"Resampled token index: {sampled_token_index}\")\n",
    "        print(f\"Resampled word: {sampled_word}\")\n",
    "\n",
    "        # Check if decoding is complete\n",
    "        if len(decoded_sentence) == len(scrambled_words) or sum(word_count.values()) == 0:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = np.zeros((1, max_seq_length - 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    # Validate that all words were used; if not, add missing words\n",
    "    missing_words = [word for word in scrambled_words if word not in used_words]\n",
    "    decoded_sentence.extend(missing_words)\n",
    "\n",
    "    return \" \".join(decoded_sentence).strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, scrambled_sentence):\n",
    "    \"\"\"\n",
    "    Decode a scrambled sentence while ensuring the output is a permutation\n",
    "    of the words in the scrambled sentence and avoiding consecutive repetitions.\n",
    "    \"\"\"\n",
    "    # Encode the input to get the context vector\n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Tokenize the scrambled sentence to get word counts\n",
    "    scrambled_words = scrambled_sentence.split()\n",
    "    word_count = Counter(scrambled_words)\n",
    "\n",
    "    # Generate the initial target sequence with the start token\n",
    "    target_seq = np.zeros((1, max_seq_length - 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[\"<start>\"]\n",
    "\n",
    "    # Initialize variables for decoding\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    used_words = set()\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Predict the next token probabilities\n",
    "        output_tokens = decoder_model.predict([target_seq, encoder_output])\n",
    "\n",
    "        # Create a mask for valid words\n",
    "        valid_word_indices = []\n",
    "        for word, count in word_count.items():\n",
    "            if count > 0:  # Only include words still available in scrambled input\n",
    "                token_index = tokenizer.word_index.get(word, None)\n",
    "                if token_index is not None:\n",
    "                    valid_word_indices.append(token_index)\n",
    "\n",
    "        # Mask out probabilities of words that are not in the scrambled set\n",
    "        if valid_word_indices:\n",
    "            mask = np.ones(output_tokens[0, -1, :].shape, dtype=bool)\n",
    "            mask[valid_word_indices] = False  # Only allow valid word indices\n",
    "            output_tokens[0, -1, mask] = 0\n",
    "        else:\n",
    "            # No valid words left, terminate decoding\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Resample a valid word, avoiding consecutive repetitions\n",
    "        sorted_indices = output_tokens[0, -1, :].argsort()[::-1]  # Sort probabilities in descending order\n",
    "        for token_index in sorted_indices:\n",
    "            sampled_word = tokenizer.index_word.get(token_index, None)\n",
    "            if (\n",
    "                sampled_word in word_count and\n",
    "                word_count[sampled_word] > 0 and\n",
    "                (not decoded_sentence or sampled_word != decoded_sentence[-1])  # Avoid consecutive repetition\n",
    "            ):\n",
    "                break\n",
    "        else:\n",
    "            # If no valid word is found (edge case), terminate\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Add the sampled word to the decoded sentence\n",
    "        decoded_sentence.append(sampled_word)\n",
    "        word_count[sampled_word] -= 1\n",
    "        used_words.add(sampled_word)\n",
    "\n",
    "        # Debugging prints\n",
    "        print(f\"Resampled token index: {token_index}\")\n",
    "        print(f\"Resampled word: {sampled_word}\")\n",
    "\n",
    "        # Check if decoding is complete\n",
    "        if len(decoded_sentence) == len(scrambled_words) or sum(word_count.values()) == 0:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = np.zeros((1, max_seq_length - 1))\n",
    "        target_seq[0, 0] = token_index\n",
    "\n",
    "    # Validate that all words were used; if not, add missing words\n",
    "    missing_words = [word for word in scrambled_words if word not in used_words]\n",
    "    decoded_sentence.extend(missing_words)\n",
    "\n",
    "    return \" \".join(decoded_sentence).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newest \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def decode_sequence(input_seq, scrambled_sentence):\n",
    "    \"\"\"\n",
    "    Decode a scrambled sentence while ensuring the output is a permutation\n",
    "    of the words in the scrambled sentence and avoiding consecutive repetitions.\n",
    "    \"\"\"\n",
    "    # Encode the input to get the context vector\n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Tokenize the scrambled sentence to get word counts\n",
    "    scrambled_words = scrambled_sentence.split()\n",
    "    word_count = Counter(scrambled_words)\n",
    "\n",
    "    # Generate the initial target sequence with the start token\n",
    "    target_seq = np.zeros((1, max_seq_length - 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[\"<start>\"]\n",
    "\n",
    "    # Initialize variables for decoding\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Predict the next token probabilities\n",
    "        output_tokens = decoder_model.predict([target_seq, encoder_output])\n",
    "\n",
    "        # Create a mask for valid words\n",
    "        valid_word_indices = []\n",
    "        for word, count in word_count.items():\n",
    "            if count > 0:  # Only include words still available in scrambled input\n",
    "                token_index = tokenizer.word_index.get(word, None)\n",
    "                if token_index is not None:\n",
    "                    valid_word_indices.append(token_index)\n",
    "\n",
    "        # Mask out probabilities of words that are not in the scrambled set\n",
    "        if valid_word_indices:\n",
    "            mask = np.ones(output_tokens[0, -1, :].shape, dtype=bool)\n",
    "            mask[valid_word_indices] = False  # Only allow valid word indices\n",
    "            output_tokens[0, -1, mask] = 0\n",
    "        else:\n",
    "            # No valid words left, terminate decoding\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Resample a valid word, avoiding consecutive repetitions\n",
    "        sorted_indices = output_tokens[0, -1, :].argsort()[::-1]  # Sort probabilities in descending order\n",
    "        sampled_word = None\n",
    "        for token_index in sorted_indices:\n",
    "            word_candidate = tokenizer.index_word.get(token_index, None)\n",
    "            if (\n",
    "                word_candidate in word_count and\n",
    "                word_count[word_candidate] > 0 and\n",
    "                (not decoded_sentence or word_candidate != decoded_sentence[-1])  # Avoid consecutive repetition\n",
    "            ):\n",
    "                sampled_word = word_candidate\n",
    "                break\n",
    "\n",
    "        # If no valid word is found, terminate\n",
    "        if sampled_word is None:\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Add the sampled word to the decoded sentence\n",
    "        decoded_sentence.append(sampled_word)\n",
    "        word_count[sampled_word] -= 1\n",
    "\n",
    "        # Debugging prints\n",
    "        print(f\"Resampled token index: {token_index}\")\n",
    "        print(f\"Resampled word: {sampled_word}\")\n",
    "\n",
    "        # Check if decoding is complete\n",
    "        if sum(word_count.values()) == 0:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = np.zeros((1, max_seq_length - 1))\n",
    "        target_seq[0, 0] = token_index\n",
    "\n",
    "    # Ensure all words are included\n",
    "    missing_words = []\n",
    "    for word, count in word_count.items():\n",
    "        if count > 0:\n",
    "            missing_words.extend([word] * count)\n",
    "    decoded_sentence.extend(missing_words)\n",
    "\n",
    "    return \" \".join(decoded_sentence).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
      "Resampled token index: 434\n",
      "Resampled word: cat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 17\n",
      "Resampled word: on\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 151\n",
      "Resampled word: sat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "Scrambled: on the sat mat cat the\n",
      "Unscrambled: cat on the the sat mat\n"
     ]
    }
   ],
   "source": [
    "# toss together some tests\n",
    "#scrambled_input = \"row your boat down the stream gently row row\"\n",
    "scrambled_input =\"on the sat mat cat the\"\n",
    "#scrambled_input =\"are ? you where\"\n",
    "\n",
    "input_sequence = pad_sequences(tokenizer.texts_to_sequences([scrambled_input]), maxlen=max_seq_length, padding=\"post\")\n",
    "unscrambled_sentence = decode_sequence(input_sequence, scrambled_input)\n",
    "print(f\"Scrambled: {scrambled_input}\")\n",
    "print(f\"Unscrambled: {unscrambled_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "Resampled token index: 4277\n",
      "Resampled word: reindeer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 821\n",
      "Resampled word: walk\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "Resampled token index: 226\n",
      "Resampled word: night\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "Resampled token index: 669\n",
      "Resampled word: sleep\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Resampled token index: 878\n",
      "Resampled word: laugh\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 154\n",
      "Resampled word: give\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "Resampled token index: 1842\n",
      "Resampled word: family\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Scrambled: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and\n",
      "Unscrambled: reindeer walk night sleep laugh give ornament family the and advent chimney elf fireplace gingerbread mistletoe scrooge jump drive bake\n"
     ]
    }
   ],
   "source": [
    "text_0 = \"advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge\"\n",
    "text_1 = \"advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and\"\n",
    "text_2 = \"yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice\"\n",
    "text_3 = \"yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap\"\n",
    "text_4 = \"hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\"\n",
    "text_5 = \"advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\"\n",
    "scrambled_input = text_1\n",
    "input_sequence = pad_sequences(tokenizer.texts_to_sequences([scrambled_input]), maxlen=max_seq_length, padding=\"post\")\n",
    "unscrambled_sentence = decode_sequence(input_sequence, scrambled_input)\n",
    "print(f\"Scrambled: {scrambled_input}\")\n",
    "print(f\"Unscrambled: {unscrambled_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Perpexity using kaggle's competition script \n",
    "%run '/home/ec2-user/kaggle/rudolph/perplexityCalc.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/home/ec2-user/kaggle/rudolph/sample_submission.csv\"\n",
    "input = pd.read_csv(csv_file)\n",
    "input = input.drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge\n",
      "Row 1: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and\n",
      "Row 2: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice\n",
      "Row 3: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap\n",
      "Row 4: hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\n",
      "Row 5: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through each row in column 'XX'\n",
    "for index, value in input['text'].items():\n",
    "    # Create a variable for the string in column 'XX'\n",
    "    current_string = value\n",
    "    print(f\"Row {index}: {current_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
      "Resampled token index: 4277\n",
      "Resampled word: reindeer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 1842\n",
      "Resampled word: family\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Scrambled: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge\n",
      "Unscrambled: reindeer ornament family advent chimney elf fireplace gingerbread mistletoe scrooge\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "Resampled token index: 4277\n",
      "Resampled word: reindeer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "Resampled token index: 821\n",
      "Resampled word: walk\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 226\n",
      "Resampled word: night\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 669\n",
      "Resampled word: sleep\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 878\n",
      "Resampled word: laugh\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 154\n",
      "Resampled word: give\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 1842\n",
      "Resampled word: family\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Scrambled: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and\n",
      "Unscrambled: reindeer walk night sleep laugh give ornament family the and advent chimney elf fireplace gingerbread mistletoe scrooge jump drive bake\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 5913\n",
      "Resampled word: nice\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Scrambled: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice\n",
      "Unscrambled: nice ornament yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking holly jingle beard naughty\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 640\n",
      "Resampled word: visit\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 20\n",
      "Resampled word: is\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Resampled token index: 5913\n",
      "Resampled word: nice\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 5\n",
      "Resampled word: of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Scrambled: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap\n",
      "Unscrambled: visit is nice ornament the and of yuletide decorations gifts cheer cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking holly jingle beard naughty sing eat relax unwrap\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 1783\n",
      "Resampled word: joy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 744\n",
      "Resampled word: peace\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "Resampled token index: 226\n",
      "Resampled word: night\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "Resampled token index: 11\n",
      "Resampled word: you\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 881\n",
      "Resampled word: game\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 4\n",
      "Resampled word: to\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 13\n",
      "Resampled word: it\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 2107\n",
      "Resampled word: card\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 30\n",
      "Resampled word: not\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
      "Resampled token index: 21\n",
      "Resampled word: as\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 489\n",
      "Resampled word: wish\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 53\n",
      "Resampled word: we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 7\n",
      "Resampled word: in\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 1959\n",
      "Resampled word: season\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 1725\n",
      "Resampled word: dream\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 860\n",
      "Resampled word: merry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 554\n",
      "Resampled word: hope\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 12\n",
      "Resampled word: with\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 1013\n",
      "Resampled word: wonder\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 1912\n",
      "Resampled word: doll\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 2522\n",
      "Resampled word: paper\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
      "Resampled token index: 34\n",
      "Resampled word: have\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 40\n",
      "Resampled word: from\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 1337\n",
      "Resampled word: star\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 356\n",
      "Resampled word: believe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 14\n",
      "Resampled word: that\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 5\n",
      "Resampled word: of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "Scrambled: hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\n",
      "Unscrambled: joy peace night you game to it card not as wish we in season dream merry hope with wonder doll paper have from star the and believe that of hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle toy workshop greeting wrapping bow fireplace cookie milk wreath angel kaggle\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 1783\n",
      "Resampled word: joy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 4277\n",
      "Resampled word: reindeer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 744\n",
      "Resampled word: peace\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 821\n",
      "Resampled word: walk\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 226\n",
      "Resampled word: night\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 11\n",
      "Resampled word: you\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 226\n",
      "Resampled word: night\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 881\n",
      "Resampled word: game\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 4\n",
      "Resampled word: to\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Resampled token index: 640\n",
      "Resampled word: visit\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 13\n",
      "Resampled word: it\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 2107\n",
      "Resampled word: card\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 30\n",
      "Resampled word: not\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 21\n",
      "Resampled word: as\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n",
      "Resampled token index: 489\n",
      "Resampled word: wish\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 53\n",
      "Resampled word: we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 7\n",
      "Resampled word: in\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 1959\n",
      "Resampled word: season\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
      "Resampled token index: 1725\n",
      "Resampled word: dream\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 669\n",
      "Resampled word: sleep\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 860\n",
      "Resampled word: merry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 554\n",
      "Resampled word: hope\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 12\n",
      "Resampled word: with\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 1013\n",
      "Resampled word: wonder\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 1912\n",
      "Resampled word: doll\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "Resampled token index: 2522\n",
      "Resampled word: paper\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 34\n",
      "Resampled word: have\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 878\n",
      "Resampled word: laugh\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Resampled token index: 20\n",
      "Resampled word: is\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 5913\n",
      "Resampled word: nice\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n",
      "Resampled token index: 154\n",
      "Resampled word: give\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 1842\n",
      "Resampled word: family\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Resampled token index: 3862\n",
      "Resampled word: ornament\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Resampled token index: 40\n",
      "Resampled word: from\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 1337\n",
      "Resampled word: star\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Resampled token index: 2\n",
      "Resampled word: and\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "Resampled token index: 356\n",
      "Resampled word: believe\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Resampled token index: 14\n",
      "Resampled word: that\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "Resampled token index: 5\n",
      "Resampled word: of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Scrambled: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy workshop wonder believe dream hope peace joy merry season greeting card wrapping paper bow fireplace night cookie milk star wish wreath angel the to of and in that have it not with as you from we kaggle\n",
      "Unscrambled: joy reindeer peace walk night you night game to visit it card not as wish we in season dream sleep merry hope with wonder doll paper have laugh is nice give ornament family ornament from star the and the and the and believe that of advent chimney chimney elf fireplace fireplace gingerbread mistletoe scrooge jump drive bake yuletide decorations gifts cheer cheer holiday carol magi nutcracker polar grinch sleigh workshop workshop stocking holly jingle beard naughty sing of eat relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle toy greeting wrapping bow cookie milk wreath angel kaggle\n"
     ]
    }
   ],
   "source": [
    "output_file = []\n",
    "for index, value in input['text'].items():\n",
    "    # Create a variable for the string in column 'XX'\n",
    "    scrambled_input = value\n",
    "    #print(f\"Row {index}: {current_string}\")\n",
    "\n",
    "    input_sequence = pad_sequences(tokenizer.texts_to_sequences([scrambled_input]), maxlen=max_seq_length, padding=\"post\")\n",
    "    unscrambled_sentence = decode_sequence(input_sequence, scrambled_input)\n",
    "    output_file.append(unscrambled_sentence)\n",
    "    print(f\"Scrambled: {scrambled_input}\")\n",
    "    print(f\"Unscrambled: {unscrambled_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution counts = 0    {'reindeer': 1, 'ornament': 1, 'family': 1, 'a...\n",
      "1    {'reindeer': 1, 'walk': 1, 'night': 1, 'sleep'...\n",
      "2    {'nice': 1, 'ornament': 1, 'yuletide': 1, 'dec...\n",
      "3    {'visit': 1, 'is': 1, 'nice': 1, 'ornament': 1...\n",
      "4    {'joy': 1, 'peace': 1, 'night': 1, 'you': 1, '...\n",
      "5    {'joy': 1, 'reindeer': 1, 'peace': 1, 'walk': ...\n",
      "Name: text, dtype: object\n",
      "input counts = 0    {'advent': 1, 'chimney': 1, 'elf': 1, 'family'...\n",
      "1    {'advent': 1, 'chimney': 1, 'elf': 1, 'family'...\n",
      "2    {'yuletide': 1, 'decorations': 1, 'gifts': 1, ...\n",
      "3    {'yuletide': 1, 'decorations': 1, 'gifts': 1, ...\n",
      "4    {'hohoho': 1, 'candle': 1, 'poinsettia': 1, 's...\n",
      "5    {'advent': 1, 'chimney': 2, 'elf': 1, 'family'...\n",
      "Name: text, dtype: object\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "Name: text, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "unscrambled = pd.DataFrame(output_file, columns=[\"text\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(input)\n",
    "#print(unscrambled)\n",
    "#print(output_file)\n",
    "#print(max_seq_length)\n",
    " # Check that each submitted string is a permutation of the solution string\n",
    "sol_counts = unscrambled.loc[:, 'text'].str.split().apply(Counter)\n",
    "\n",
    "print(f\"solution counts = {sol_counts}\")\n",
    "sub_counts = input.loc[:, 'text'].str.split().apply(Counter)\n",
    "\n",
    "print(f\"input counts = {sub_counts}\")\n",
    "invalid_mask = sol_counts != sub_counts\n",
    "\n",
    "if invalid_mask.any():\n",
    "    raise ParticipantVisibleError(\n",
    "        'At least one submitted string is not a valid permutation of the solution string.'\n",
    "    )\n",
    "\n",
    "print(invalid_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "Name: text, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(invalid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/gemma-2/transformers/gemma-2-9b/2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43munscrambled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclear_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/kaggle/rudolph/perplexityCalc.py:98\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(solution, submission, row_id_column_name, model_path, load_in_8bit, clear_mem)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Calculate perplexity for the submitted strings\u001b[39;00m\n\u001b[1;32m     95\u001b[0m sub_strings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(s\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     97\u001b[0m ]  \u001b[38;5;66;03m# Split and rejoin to normalize whitespace\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mPerplexityCalculator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Initialize the perplexity calculator with a pre-trained model\u001b[39;00m\n\u001b[1;32m    102\u001b[0m perplexities \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mget_perplexity(\n\u001b[1;32m    103\u001b[0m     sub_strings\n\u001b[1;32m    104\u001b[0m )  \u001b[38;5;66;03m# Calculate perplexity for each submitted string\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clear_mem:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Just move on if it fails. Not essential if we have the score.\u001b[39;00m\n",
      "File \u001b[0;32m~/kaggle/rudolph/perplexityCalc.py:140\u001b[0m, in \u001b[0;36mPerplexityCalculator.__init__\u001b[0;34m(self, model_path, load_in_8bit, device_map)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     model_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    137\u001b[0m     load_in_8bit: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m     device_map: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241m.\u001b[39mAutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# Configure model loading based on quantization setting and device availability\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n",
    "score(unscrambled, input, 'id', model_path=model_path, clear_mem=True) > 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
