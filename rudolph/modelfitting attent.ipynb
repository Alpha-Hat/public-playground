{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 23:03:50.857749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733267031.080385   37780 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733267031.145962   37780 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 23:03:51.800054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, MultiHeadAttention, LayerNormalization, Add\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "Story text extracted successfully:\n",
      "A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\n",
      "\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\n",
      "Do not attempt too much at once.\n",
      "\n",
      "\n",
      "\n",
      "Return to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\n",
      "Or read more short stories for kids in ourChildren's Library\n",
      "into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren's filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then\n"
     ]
    }
   ],
   "source": [
    "%run '/home/ec2-user/kaggle/rudolph/dataPrep.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\n",
      "\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\n",
      "Do not attempt too much at once.\n",
      "\n",
      "\n",
      "\n",
      "Return to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\n",
      "Or read more short stories for kids in ourChildren's Library\n",
      "into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren's filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then\n"
     ]
    }
   ],
   "source": [
    "print(stories[0][0])\n",
    "print(stories[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset: Pairs of original and scrambled sentences \n",
    "\"\"\"\n",
    "sentences = [\n",
    "    (\"I love programming\", \"programming I love\"),\n",
    "    (\"Keras makes deep learning easy\", \"makes easy Keras deep learning\"),\n",
    "    (\"The cat sat on the mat\", \"on the mat The cat sat\"),\n",
    "    (\"Hello world\", \"world Hello\"),\n",
    "    (\"Pine Cone and Pepper Pot ran after her. Jeremy Mouse only stuck his head out of the snow cave. He didn’t want Jack Frost to nip his toes and certainly not his tail! Jack Frost! Jack Frost! cried Tiptoes. We’ve come to pay a visit. Jack Frost landed next to them. He was pale, icy blue, and his arms and fingers were long and glistening. His eyes were sharp, and his wings crackled like breaking ice whenever he moved. He looked so fierce that Pine Cone and Pepper Pot were afraid to open their mouths. It became so chilly they wrapped their beards round their necks and pulled their hats over their ears.\", \"snow he beards only fingers so out their We’ve of and came his sharp, they Cone her. afraid glistening. he Jack long, their It Jack He open his Pot! was to Pot and hats nip after not He necks the ears. Jeremy over Jack next icy Mouse round moved. He tail! was pale, the pay their icy pine wrapped their didn’t heads ice fierce glistening. mouths. breaking over pay Jack next like arms his moved. and certainly! only out was the look Tiptoes over not mouths. and he his to Pepper afraid cave. him Jeremy stuck crackled came blue, pulled ran his round with tail! He them. Mouse after didn’t nip fingers wings their not tail! mouse Pot afraid stuck arms of toes icy Cone was them pay. Pine wings came Pepper their He fierce long his wings Cone hats icy his over and next certainly Jack after ears. glistening. pay tiptoes! like pine ran was icy cave! certainly moved the.\"),\n",
    "    (\"Machine learning is fascinating\", \"fascinating Machine is learning\"),\n",
    "]\n",
    "\"\"\"\n",
    "sentences = stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I love programming', 'programming I love')\n",
      "('A Boy was given permission to put his hand into a pitcher to get some filberts. But he took such a great fistful that he could not draw his hand out again. There he stood, unwilling to give up a single filbert and yet unable to get them all out at once. Vexed and disappointed he began to cry.\\n\"My boy,\" said his mother, \"be satisfied with half the nuts you have taken and you will easily get your hand out. Then perhaps you may have some more filberts some other time.\"\\nDo not attempt too much at once.\\n\\n\\n\\nReturn to theAesoplibrary , or . . . Read the next short story;The Boy And The Nettle\\nOr read more short stories for kids in ourChildren\\'s Library', 'into other to easily out But his theAesoplibrary , Library them great out have There at mother, stories The took you was with hand to may his Boy Nettle your not at boy,\" and not \"My a taken stood, once. said up next filbert once. or began and perhaps fistful Vexed you that too single . more half put he ourChildren\\'s filberts satisfied much . Do hand he get give a out. filberts. the cry. to he unable to to all Read Or more . such Return yet short a A for story;The to short and And some you time.\" could have the get \"be hand draw Boy in permission disappointed will pitcher nuts read some get kids he his again. unwilling attempt given some Then')\n"
     ]
    }
   ],
   "source": [
    "#print(sentences[0])\n",
    "#print(stories[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 23:04:58.810025: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "#Original from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Add, Dense\n",
    "\n",
    "# Add <start> and <end> tokens to the original sentences\n",
    "original_sentences = [f\"<start> {s[0]} <end>\" for s in sentences]\n",
    "scrambled_sentences = [s[1] for s in sentences]\n",
    "\n",
    "# Tokenize and preprocess sentences\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(original_sentences + scrambled_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "max_seq_length = max(\n",
    "    max(len(seq.split()) for seq in scrambled_sentences),\n",
    "    max(len(seq.split()) for seq in original_sentences),\n",
    ")\n",
    "\n",
    "# Convert sentences to sequences and pad\n",
    "input_sequences = pad_sequences(tokenizer.texts_to_sequences(scrambled_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "target_sequences = pad_sequences(tokenizer.texts_to_sequences(original_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "\n",
    "# Create target sequences for teacher forcing\n",
    "target_input_sequences = target_sequences[:, :-1]\n",
    "target_output_sequences = target_sequences[:, 1:]\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 200\n",
    "latent_dim = 200\n",
    "num_heads = 4\n",
    "\n",
    "# Define Encoder\n",
    "encoder_inputs = Input(shape=(max_seq_length,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs = Dense(latent_dim)(encoder_embedding)  # Encoder output for attention\n",
    "\n",
    "# Define Decoder with Transformer architecture\n",
    "decoder_inputs = Input(shape=(max_seq_length - 1,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "\n",
    "# Self-Attention in Decoder\n",
    "decoder_self_attention = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_embedding, decoder_embedding)\n",
    "decoder_self_attention = Add()([decoder_embedding, decoder_self_attention])  # Residual connection\n",
    "decoder_self_attention = LayerNormalization()(decoder_self_attention)\n",
    "\n",
    "# Cross-Attention between Encoder and Decoder\n",
    "decoder_cross_attention = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_self_attention, encoder_outputs)\n",
    "decoder_cross_attention = Add()([decoder_self_attention, decoder_cross_attention])  # Residual connection\n",
    "decoder_cross_attention = LayerNormalization()(decoder_cross_attention)\n",
    "\n",
    "# Feed-forward layer\n",
    "decoder_ffn = Dense(latent_dim * 4, activation=\"relu\")(decoder_cross_attention)\n",
    "decoder_ffn = Dense(latent_dim)(decoder_ffn)\n",
    "decoder_ffn = Add()([decoder_cross_attention, decoder_ffn])  # Residual connection\n",
    "decoder_ffn = LayerNormalization()(decoder_ffn)\n",
    "\n",
    "# Final output layer\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(decoder_ffn)\n",
    "\n",
    "# Define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Prepare data for training\n",
    "decoder_target_output = np.expand_dims(target_output_sequences, -1)\n",
    "X_train, X_test, y_train, y_test, decoder_y_train, decoder_y_test = train_test_split(\n",
    "    input_sequences, target_input_sequences, decoder_target_output, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Add <start> and <end> tokens to the original sentences\n",
    "original_sentences = [f\"<start> {s[0]} <end>\" for s in sentences]\n",
    "scrambled_sentences = [s[1] for s in sentences]\n",
    "\n",
    "# Tokenize and preprocess sentences\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(original_sentences + scrambled_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "max_seq_length = max(\n",
    "    max(len(seq.split()) for seq in scrambled_sentences),\n",
    "    max(len(seq.split()) for seq in original_sentences),\n",
    ")\n",
    "\n",
    "# Convert sentences to sequences and pad\n",
    "input_sequences = pad_sequences(tokenizer.texts_to_sequences(scrambled_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "target_sequences = pad_sequences(tokenizer.texts_to_sequences(original_sentences), maxlen=max_seq_length, padding=\"post\")\n",
    "\n",
    "# Create target sequences for teacher forcing\n",
    "target_input_sequences = target_sequences[:, :-1]\n",
    "target_output_sequences = target_sequences[:, 1:]\n",
    "\n",
    "embedding_dim = 256\n",
    "latent_dim = 256\n",
    "num_heads = 4\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_seq_length,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs = Dense(latent_dim)(encoder_embedding)\n",
    "\n",
    "# Additional encoder layer\n",
    "encoder_dense_2 = Dense(latent_dim, activation=\"relu\")(encoder_outputs)\n",
    "encoder_outputs = Add()([encoder_outputs, encoder_dense_2])  # Residual connection\n",
    "encoder_outputs = LayerNormalization()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_seq_length - 1,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "\n",
    "# Self-Attention\n",
    "decoder_self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=latent_dim)(decoder_embedding, decoder_embedding)\n",
    "decoder_self_attention = Add()([decoder_embedding, decoder_self_attention])\n",
    "decoder_self_attention = LayerNormalization()(decoder_self_attention)\n",
    "\n",
    "# Cross-Attention\n",
    "decoder_cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=latent_dim)(decoder_self_attention, encoder_outputs)\n",
    "decoder_cross_attention = Add()([decoder_self_attention, decoder_cross_attention])\n",
    "decoder_cross_attention = LayerNormalization()(decoder_cross_attention)\n",
    "\n",
    "# Feed-forward layers\n",
    "decoder_ffn = Dense(latent_dim * 4, activation=\"relu\")(decoder_cross_attention)\n",
    "decoder_ffn = Dense(latent_dim)(decoder_ffn)\n",
    "decoder_ffn = Add()([decoder_cross_attention, decoder_ffn])  # Residual connection\n",
    "decoder_ffn = LayerNormalization()(decoder_ffn)\n",
    "\n",
    "# Additional feed-forward block\n",
    "decoder_ffn_2 = Dense(latent_dim * 4, activation=\"relu\")(decoder_ffn)\n",
    "decoder_ffn_2 = Dense(latent_dim)(decoder_ffn_2)\n",
    "decoder_ffn_2 = Add()([decoder_ffn, decoder_ffn_2])  # Residual connection\n",
    "decoder_ffn_2 = LayerNormalization()(decoder_ffn_2)\n",
    "\n",
    "# Output layer\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(decoder_ffn_2)\n",
    "\n",
    "# Compile model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Prepare data for training\n",
    "decoder_target_output = np.expand_dims(target_output_sequences, -1)\n",
    "X_train, X_test, y_train, y_test, decoder_y_train, decoder_y_test = train_test_split(\n",
    "    input_sequences, target_input_sequences, decoder_target_output, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5353 - loss: 3.2404 - val_accuracy: 0.4976 - val_loss: 3.8861\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5368 - loss: 3.1796 - val_accuracy: 0.4999 - val_loss: 3.8801\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5521 - loss: 3.1179 - val_accuracy: 0.4992 - val_loss: 3.8727\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.5582 - loss: 3.0593 - val_accuracy: 0.5001 - val_loss: 3.8715\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5716 - loss: 3.0009 - val_accuracy: 0.5021 - val_loss: 3.8731\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5804 - loss: 2.9439 - val_accuracy: 0.5020 - val_loss: 3.8735\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5845 - loss: 2.8869 - val_accuracy: 0.5016 - val_loss: 3.8779\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5892 - loss: 2.8338 - val_accuracy: 0.5017 - val_loss: 3.8822\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.5957 - loss: 2.7791 - val_accuracy: 0.5013 - val_loss: 3.8845\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6011 - loss: 2.7261 - val_accuracy: 0.5018 - val_loss: 3.8851\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6037 - loss: 2.6743 - val_accuracy: 0.5029 - val_loss: 3.8873\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6077 - loss: 2.6239 - val_accuracy: 0.5023 - val_loss: 3.8928\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6124 - loss: 2.5745 - val_accuracy: 0.5016 - val_loss: 3.9005\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6164 - loss: 2.5268 - val_accuracy: 0.5016 - val_loss: 3.9065\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6188 - loss: 2.4800 - val_accuracy: 0.5027 - val_loss: 3.9104\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6198 - loss: 2.4342 - val_accuracy: 0.5025 - val_loss: 3.9153\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6209 - loss: 2.3902 - val_accuracy: 0.5020 - val_loss: 3.9228\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6226 - loss: 2.3477 - val_accuracy: 0.5011 - val_loss: 3.9317\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6234 - loss: 2.3068 - val_accuracy: 0.5013 - val_loss: 3.9392\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6241 - loss: 2.2670 - val_accuracy: 0.5012 - val_loss: 3.9463\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6247 - loss: 2.2289 - val_accuracy: 0.5000 - val_loss: 3.9547\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6251 - loss: 2.1924 - val_accuracy: 0.4999 - val_loss: 3.9646\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6261 - loss: 2.1571 - val_accuracy: 0.5005 - val_loss: 3.9738\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6271 - loss: 2.1232 - val_accuracy: 0.5007 - val_loss: 3.9823\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6277 - loss: 2.0906 - val_accuracy: 0.5001 - val_loss: 3.9928\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6283 - loss: 2.0594 - val_accuracy: 0.4994 - val_loss: 4.0054\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6289 - loss: 2.0293 - val_accuracy: 0.4988 - val_loss: 4.0169\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6294 - loss: 2.0005 - val_accuracy: 0.4989 - val_loss: 4.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6300 - loss: 1.9730 - val_accuracy: 0.4992 - val_loss: 4.0387\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6306 - loss: 1.9468 - val_accuracy: 0.4991 - val_loss: 4.0519\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6317 - loss: 1.9216 - val_accuracy: 0.4987 - val_loss: 4.0632\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6330 - loss: 1.8975 - val_accuracy: 0.4995 - val_loss: 4.0742\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6340 - loss: 1.8746 - val_accuracy: 0.4993 - val_loss: 4.0875\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6350 - loss: 1.8527 - val_accuracy: 0.4993 - val_loss: 4.1004\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6360 - loss: 1.8317 - val_accuracy: 0.4993 - val_loss: 4.1126\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6373 - loss: 1.8117 - val_accuracy: 0.4991 - val_loss: 4.1254\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 0.6378 - loss: 1.7926 - val_accuracy: 0.4987 - val_loss: 4.1375\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6388 - loss: 1.7743 - val_accuracy: 0.4988 - val_loss: 4.1507\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6401 - loss: 1.7568 - val_accuracy: 0.4980 - val_loss: 4.1618\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6417 - loss: 1.7401 - val_accuracy: 0.4980 - val_loss: 4.1751\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6428 - loss: 1.7242 - val_accuracy: 0.4974 - val_loss: 4.1893\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6441 - loss: 1.7090 - val_accuracy: 0.4969 - val_loss: 4.2014\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6452 - loss: 1.6944 - val_accuracy: 0.4967 - val_loss: 4.2145\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6466 - loss: 1.6805 - val_accuracy: 0.4971 - val_loss: 4.2255\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6478 - loss: 1.6674 - val_accuracy: 0.4962 - val_loss: 4.2418\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6486 - loss: 1.6558 - val_accuracy: 0.4962 - val_loss: 4.2470\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6484 - loss: 1.6498 - val_accuracy: 0.4951 - val_loss: 4.2895\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6493 - loss: 1.6498 - val_accuracy: 0.4977 - val_loss: 4.2572\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6475 - loss: 1.6352 - val_accuracy: 0.4954 - val_loss: 4.2909\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 0.6517 - loss: 1.6154 - val_accuracy: 0.4950 - val_loss: 4.3251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f035b8c51f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(\n",
    "    [X_train, y_train], decoder_y_train,\n",
    "    validation_data=([X_test, y_test], decoder_y_test),\n",
    "    batch_size=60,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in SavedModel format\n",
    "model.save(\"/home/ec2-user/kaggle/rudolph/model_v0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define inference models\n",
    "# Encoder model remains the same\n",
    "encoder_model = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# Decoder for inference\n",
    "decoder_inputs_inf = Input(shape=(max_seq_length - 1,))\n",
    "decoder_embedding_inf = Embedding(vocab_size, embedding_dim)(decoder_inputs_inf)\n",
    "\n",
    "decoder_self_attention_inf = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_embedding_inf, decoder_embedding_inf)\n",
    "decoder_self_attention_inf = Add()([decoder_embedding_inf, decoder_self_attention_inf])\n",
    "decoder_self_attention_inf = LayerNormalization()(decoder_self_attention_inf)\n",
    "\n",
    "decoder_cross_attention_inf = MultiHeadAttention(num_heads=4, key_dim=latent_dim)(decoder_self_attention_inf, encoder_outputs)\n",
    "decoder_cross_attention_inf = Add()([decoder_self_attention_inf, decoder_cross_attention_inf])\n",
    "decoder_cross_attention_inf = LayerNormalization()(decoder_cross_attention_inf)\n",
    "\n",
    "decoder_ffn_inf = Dense(latent_dim * 4, activation=\"relu\")(decoder_cross_attention_inf)\n",
    "decoder_ffn_inf = Dense(latent_dim)(decoder_ffn_inf)\n",
    "decoder_ffn_inf = Add()([decoder_cross_attention_inf, decoder_ffn_inf])\n",
    "decoder_ffn_inf = LayerNormalization()(decoder_ffn_inf)\n",
    "\n",
    "decoder_outputs_inf = Dense(vocab_size, activation=\"softmax\")(decoder_ffn_inf)\n",
    "\n",
    "decoder_model = Model([decoder_inputs_inf, encoder_outputs], decoder_outputs_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to decode scrambled sentences\n",
    "def decode_sequence(input_seq, scrambled_sentence):\n",
    "    \"\"\"\n",
    "    Decode a scrambled sentence while ensuring the output is a permutation\n",
    "    of the words in the scrambled sentence.\n",
    "    \"\"\"\n",
    "    # Encode the input to get the context vector\n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Tokenize the scrambled sentence to get word counts\n",
    "    scrambled_words = scrambled_sentence.split()\n",
    "    word_count = Counter(scrambled_words)\n",
    "\n",
    "    # Generate the initial target sequence with the start token\n",
    "    target_seq = np.zeros((1, max_seq_length - 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[\"<start>\"]\n",
    "\n",
    "    # Initialize variables for decoding\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    used_words = set()\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Predict the next token probabilities\n",
    "        output_tokens = decoder_model.predict([target_seq, encoder_output])\n",
    "\n",
    "        # Create a mask for valid words\n",
    "        valid_word_indices = []\n",
    "        for word, count in word_count.items():\n",
    "            if count > 0:  # Only include words still available in scrambled input\n",
    "                token_index = tokenizer.word_index.get(word, None)\n",
    "                if token_index is not None:\n",
    "                    valid_word_indices.append(token_index)\n",
    "\n",
    "        # Mask out probabilities of invalid words\n",
    "        if valid_word_indices:\n",
    "            mask = np.ones(output_tokens[0, -1, :].shape, dtype=bool)\n",
    "            mask[valid_word_indices] = False  # Only allow valid word indices\n",
    "            output_tokens[0, -1, mask] = 0\n",
    "        else:\n",
    "            # No valid words left, terminate decoding\n",
    "            stop_condition = True\n",
    "            continue\n",
    "\n",
    "        # Resample a valid word\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, None)\n",
    "\n",
    "        # Ensure the sampled word is valid and not repeating excessively\n",
    "        if sampled_word in word_count and word_count[sampled_word] > 0:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "            word_count[sampled_word] -= 1\n",
    "            used_words.add(sampled_word)\n",
    "\n",
    "        # Debugging prints\n",
    "        print(f\"Resampled token index: {sampled_token_index}\")\n",
    "        print(f\"Resampled word: {sampled_word}\")\n",
    "\n",
    "        # Check if decoding is complete\n",
    "        if len(decoded_sentence) == len(scrambled_words) or sum(word_count.values()) == 0:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = np.zeros((1, max_seq_length - 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    # Validate that all words were used; if not, add missing words\n",
    "    missing_words = [word for word in scrambled_words if word not in used_words]\n",
    "    decoded_sentence.extend(missing_words)\n",
    "\n",
    "    return \" \".join(decoded_sentence).strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 151\n",
      "Resampled word: sat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "Resampled token index: 434\n",
      "Resampled word: cat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Resampled token index: 17\n",
      "Resampled word: on\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Resampled token index: 1\n",
      "Resampled word: the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "Scrambled: on the sat mat cat the\n",
      "Unscrambled: sat cat on the the mat\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "#scrambled_input = \"row your boat down the stream gently row row\"\n",
    "scrambled_input =\"on the sat mat cat the\"\n",
    "#scrambled_input =\"are ? you where\"\n",
    "\n",
    "input_sequence = pad_sequences(tokenizer.texts_to_sequences([scrambled_input]), maxlen=max_seq_length, padding=\"post\")\n",
    "unscrambled_sentence = decode_sequence(input_sequence, scrambled_input)\n",
    "print(f\"Scrambled: {scrambled_input}\")\n",
    "print(f\"Unscrambled: {unscrambled_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'on': 1, 'the': 1, 'mat': 1, 'The': 1, 'cat': 1, 'sat': 1})\n",
      "['<start> I love programming <end>', '<start> Keras makes deep learning easy <end>', '<start> The cat sat on the mat <end>', '<start> Hello world <end>', '<start> Machine learning is fascinating <end>']\n",
      "['programming I love', 'makes easy Keras deep learning', 'on the mat The cat sat', 'world Hello', 'fascinating Machine is learning']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "scrambled_sentence = \"on the mat The cat sat\"\n",
    "scrambled_words = scrambled_sentence.split()\n",
    "print(Counter(scrambled_words))\n",
    "print(original_sentences)\n",
    "print(scrambled_sentences)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
